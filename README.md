# EnvelopeDB ğŸ“¦ `v0.1.0-stable`

**EnvelopeDB** is a high-performance, distributed Key-Value storage engine implemented in Nim. It combines the simplicity and extreme write speed of Bitcask with the massive scalability of LSM-Trees and the high availability of the Raft consensus algorithm.

[ğŸ“œ MIT License](LICENSE) | [ğŸ—ï¸ Architecture Documentation](docs/ARCHITECTURE.md) | [ğŸ“– Usage Guide](docs/USAGE.md)

---

## ğŸ”¥ Key Features

- **Distributed Replication (Raft)**: 3-node cluster support with automated leader election and persistent log replication.
- **LSM-Tree Storage Layer**: Beyond-RAM scalability using **SkipList MemTables** and **SSTables**.
- **Hardware-Level I/O (mmap)**: Zero-copy read operations using memory mapping for ultra-low latency.
- **Probabilistic Optimization**: Integrated **Bloom Filters** to eliminate unnecessary disk I/O.
- **Multi-Tenant Isolation**: Logical **Buckets** for data organization.
- **Binary Integrity**: CRC32 checksums on every record with automatic corruption detection.

---

## ğŸ“Š Performance Benchmarks

EnvelopeDB is optimized for high-concurrency workloads. On standard hardware, it achieves consistent sub-millisecond latencies for both reads and writes.

### Benchmark Results
| Metric | Result |
| :--- | :--- |
| **Throughput (Concurrent)** | **~25,400 ops/s** |
| **Average Latency** | **< 2ms** |
| **Total Ops (Stress Test)** | 20,000 (50 concurrent clients) |

### Test Environment (Persistent Storage Bench)
- **CPU**: Intel(R) Core(TM) i3-6006U @ 2.00GHz
- **RAM**: 8.0GB DDR4
- **Storage**: **Mechanical HDD** (5400 RPM / ST1000LM035)
- **OS**: Linux (Ubuntu 24.04 LTS)
- **Architecture**: x86_64

> [!NOTE]
> Achieving **25,000 ops/s on a mechanical HDD** is possible because EnvelopeDB utilizes **Sequential Append-only I/O** (LSM-Tree) and **Zero-Copy Memory Mapping**, which bypasses the seek-time latency found in traditional random-access databases.

---

## ğŸ—ï¸ Architecture

EnvelopeDB uses a hybrid storage model:
1. **MemTable**: Writes are buffered in a lock-free SkipList.
2. **SSTable**: Periodic flushes create sorted, immutable disk files.
3. **Write-Ahead Log (WAL)**: Every write is durably recorded to ensure crash recovery.
4. **Raft Logic**: A consensus layer manages state across multiple nodes.

---

## ğŸš€ Getting Started

### Prerequisites
- [Nim 2.0+](https://nim-lang.org/install.html)

### Running a Cluster
Launch a 3-node cluster on localhost:

```bash
# Node 1
nim c -r src/raft.nim 9001 --clear
# Node 2
nim c -r src/raft.nim 9002 --clear
# Node 3
nim c -r src/raft.nim 9003 --clear
```

### Basic API (TCP/Text Protocol)
```text
SET user:1 {"name": "Alice", "score": 100}
GET user:1
JGET user:1 name
USE orders
SET order:99 "Pending"
```

---

## ğŸ—ºï¸ Roadmap (Future Work)

### ğŸš€ High-Performance Networking
*   **Binary Protocol**: Migrate from JSON to **Protobuf** or **FlatBuffers** to reduce serialization overhead and CPU usage.
*   **TLS 1.3 Encryption**: Secure intra-cluster and client-server communication with mTLS.
*   **Connection Pooling**: Implement a high-performance multiplexed connection handler to support thousands of concurrent clients.

### ğŸ“ˆ Global Scalability
*   **Sparse Indexing**: Reduce RAM footprint by 99% by storing only block-level anchors in memory instead of every key.
*   **Vector Search Expansion**: Add HNSW or IVFPQ indexing to support high-dimensional similarity searches for AI applications.
*   **Partitioning (Sharding)**: Support horizontal scaling by partitioning keys across multiple Raft groups.

### ğŸ›¡ï¸ Reliability & Consensus
*   **Log Compaction (Snapshots)**: Implement Raft snapshots to truncate logs and accelerate node recovery.
*   **Dynamic Membership**: Allow seamless cluster expansion (add/remove nodes) without downtime.
*   **Leader Leases**: Optimize read latency by using master leases to avoid consensus rounds for GET operations.

### ğŸ’¾ Advanced Storage Engine
*   **Multi-Level Compaction**: Implement a tiered compaction strategy (Leveled vs Size-Tiered) for different workload types.
*   **Auto-Scrubbing**: Background task to verify CRC32 checksums and detect "bit rot" on idle data.
*   **Custom Page Cache**: Implement an application-level O_DIRECT cache to gain finer control over memory than the kernel mmap cache.

### ğŸ› ï¸ Developer Ecosystem
*   **Native Client SDKs**: Official drivers for **Python**, **Go**, and **Rust**.
*   **Admin CLI**: A sophisticated terminal UI for cluster health monitoring and key-space exploration.
*   **Prometheus Integration**: Native metrics endpoint for real-time monitoring of latency, throughput, and disk usage.

---

## ğŸ¤ Contribution

Contributions are what make the open source community such an amazing place to learn, inspire, and create. Any contributions you make are **greatly appreciated**.

1. Fork the Project
2. Create your Feature Branch (`git checkout -b feature/AmazingFeature`)
3. Commit your Changes (`git commit -m 'Add some AmazingFeature'`)
4. Push to the Branch (`git push origin feature/AmazingFeature`)
5. Open a Pull Request

---

## âš–ï¸ License
Distributed under the MIT License.

---
Built with â¤ï¸.
